{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rootutils\n",
    "\n",
    "rootutils.setup_root(\"../\", indicator=\".project-root\", pythonpath=True)\n",
    "import os\n",
    "\n",
    "os.chdir(\"../\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "# plt.savefig('x.png', dpi=500, bbox_inches='tight') # 解决图片不清晰，不完整的问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "\n",
    "config = r\"logs/train/runs/2024-05-29_22-12-00/.hydra/config.yaml\"\n",
    "ckpt = r\"logs/train/runs/2024-05-29_22-12-00/checkpoints/step_090_loss0.001.ckpt\"\n",
    "config = OmegaConf.load(config)\n",
    "config.data.train_config.data_dir = \"./demo\"\n",
    "config.data.val_config.data_dir = \"./demo\"\n",
    "config.data.batch_size = 1\n",
    "config.data.batch_size_val = 1\n",
    "# ckpt = r\"./demo/step_4815_loss0.006.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = hydra.utils.instantiate(config.data)\n",
    "data_module.setup()\n",
    "batch_sample = next(iter(data_module.val_dataloader()))\n",
    "print(batch_sample[\"images\"].shape)\n",
    "show_video_line(\n",
    "    batch_sample[\"images\"][0].numpy(),\n",
    "    ncols=12,\n",
    "    vmax=0.6,\n",
    "    cbar=False,\n",
    "    out_path=None,\n",
    "    format=\"png\",\n",
    "    use_rgb=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "module = hydra.utils.instantiate(config.model)\n",
    "module.load_state_dict(torch.load(ckpt, map_location=\"cpu\")[\"state_dict\"])\n",
    "#\n",
    "print(module.model.configs)  # 输入前 7帧图像，预测后12帧图像\n",
    "# mask_true[:, t - self.configs.pre_seq_length] * frames[:, t]\n",
    "pre_seq_length = module.model.configs.pre_seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module.model.configs.pre_seq_length = 18  # 使用一张图像来预测未来18张\n",
    "module.model.configs.aft_seq_length = (\n",
    "    module.model.configs.total_length - module.model.configs.pre_seq_length\n",
    ")\n",
    "batch_sample_cp = deepcopy(batch_sample)\n",
    "batch_sample_cp[\"images\"][:, module.model.configs.pre_seq_length :, ...] = 0\n",
    "show_video_line(\n",
    "    batch_sample_cp[\"images\"][0].numpy(),\n",
    "    ncols=12,\n",
    "    vmax=0.6,\n",
    "    cbar=False,\n",
    "    out_path=None,\n",
    "    format=\"png\",\n",
    "    use_rgb=True,\n",
    ")\n",
    "with torch.no_grad():\n",
    "    img_gen, logs = module.RNN_test_step(batch_sample_cp, \"val\")\n",
    "    print(img_gen.shape)  # 缺少第一张图\n",
    "img_gen = torch.concat([batch_sample_cp[\"images\"][:, None, 0, ...], img_gen], dim=1)\n",
    "show_video_line(\n",
    "    img_gen[0].detach().numpy(),\n",
    "    ncols=12,\n",
    "    vmax=0.6,\n",
    "    cbar=False,\n",
    "    out_path=None,\n",
    "    format=\"png\",\n",
    "    use_rgb=True,\n",
    ")\n",
    "# 预测出输入状态越清晰，准确越能代表RNN学到的时间信息越成功"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module.model.configs.pre_seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import show_video_gif_multiple\n",
    "\n",
    "# 制作对比gif  -> 用于预测的，待预测的真值，预测结果\n",
    "# pre_seq_length >= 2\n",
    "show_video_gif_multiple(\n",
    "    batch_sample[\"images\"][:, : module.model.configs.pre_seq_length, ...][0],\n",
    "    batch_sample[\"images\"][:, module.model.configs.pre_seq_length :, ...][0],\n",
    "    img_gen.detach().numpy()[0],\n",
    "    use_rgb=True,\n",
    "    out_path=f\"demo/pred/pred_pre_seq-{module.model.configs.pre_seq_length}.gif\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 制作 gif 单个\n",
    "# show_video_gif_single(\n",
    "#     img_gen.detach().numpy()[0],\n",
    "#     out_path=f\"data/demo/pred/pred_pre_seq-{module.model.configs.pre_seq_length}.gif\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
